---
title: "Final_Project_Step03_MishraDebabrata"
author: "Debabrata Mishra"
date: "2023-03-03"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=TRUE}
# Assignment: Final Project Step 3 - (WEEK 11 & 12)
# Name: Mishra, Debabrata
# Problem Topic : Credit Card Fraud Detection & Prevention  

```

# 1.0 Introduction
>
Credit card fraud is a growing concern for financial institutions, merchants, and consumers alike. With the increasing use of credit cards for online transactions, the opportunity for fraudsters to commit fraudulent activities has increased dramatically. Due to the technological innovation and the emergence of a new Payment techniques, we do see huge increase in BOT attacks, Account takeover, new account fraud, cloned cards, cards-not-present schemes and mobile payments.  Such widespread acceptance of cashless transactions leads fraudsters to carry out fraudulent attacks regularly and change their tactics to avoid detection.  
>
In this paper, we aim to address the problem of detecting credit card fraud using data science techniques. The goal of this paper is to answer the research question: "How can we detect credit card fraud using data science techniques?" To answer this question, we will use machine learning models to analyze a dataset of credit card transactions. The data will be pre-processed and cleaned to remove any irrelevant information and protect the privacy of the consumers. The aim of the project is to develop a machine learning model that can identify fraudulent credit card transactions in real-time. Here is a general outline of the steps involved in a credit card fraud detection project using data science:

> Data Collection: 
>
The first step is to collect a large dataset of credit card transactions, both fraudulent and non-fraudulent. This data can be collected from various sources such as banks, financial institutions, or online platforms.

>Data Pre-processing: 
>
Once the data is collected, it needs to be cleaned, formatted, and transformed into a format that can be used for building the machine learning model. This includes dealing with missing values, converting categorical variables to numerical values, and scaling the data to ensure that all variables are on a similar scale.

>Exploratory Data Analysis (EDA): 
>
After pre-processing the data, the next step is to perform exploratory data analysis (EDA) to understand the patterns, relationships, and trends in the data. This helps in identifying the features that are important for identifying fraudulent transactions.

>Feature Engineering: 
>
Based on the insights gained from the EDA, the next step is to engineer new features that can be used to build the machine learning model. This may involve combining existing features, creating new features based on the existing features, or transforming the existing features to create new features.

>Model Selection: 
>
Once the data is pre-processed and features are engineered, the next step is to select a machine learning model that is appropriate for the task of credit card fraud detection. Popular models for this task include decision trees, random forests, support vector machines (SVMs), and neural networks.

>Model Training and Evaluation: 
>
The selected machine learning model is then trained on the pre-processed and feature-engineered data, and evaluated on a hold-out validation set. The model's performance is measured using metrics such as accuracy, precision, recall, and F1-score.

>Model Deployment: 
>
Once the model is trained and evaluated, it is deployed in the production environment to detect fraudulent credit card transactions in real-time. The model can be integrated with the existing credit card processing systems to detect fraud as soon as it occurs.

>Monitoring and Maintenance: 
>
Finally, it is important to continuously monitor the performance of the deployed model and make updates and improvements as needed. This may involve retraining the model with updated data, fine-tuning the model parameters, or updating the feature engineering process.

# 2.0 The problem statement to be addressed
>
The problem statement addressed by using machine learning models for credit card fraud is to develop a predictive model that can accurately identify fraudulent credit card transactions in real-time. Credit card fraud is a significant concern for both consumers and financial institutions, as it can result in financial losses and damage to reputation.
>
Traditionally, fraud detection has been carried out manually by financial institutions, which can be time-consuming and costly. However, with the increasing volume of credit card transactions, it has become increasingly difficult to manually identify fraudulent transactions in real-time. Therefore, machine learning models can be used to automate the process of fraud detection and identify fraudulent transactions quickly and accurately.
>
The main objective of developing a machine learning model for credit card fraud detection is to accurately distinguish between genuine and fraudulent transactions based on various features such as transaction amount, location, time, and other relevant variables. The model should be able to learn patterns and trends from historical data and apply that knowledge to detect new cases of fraud in real-time. The ultimate goal is to minimize the number of false positives and false negatives, while maximizing the accuracy of the fraud detection system.
>
With the advancement of the e-commerce platform, Customers, Merchants, and Financial institutions rely on online services to carry out their business/transactions that have led to an exponential increase in credit card fraud. Fraudulent credit card transactions lead to a loss of a huge amount of money. The design of an effective fraud detection system is necessary to reduce the losses incurred by customers and financial companies. The Data model has been done on many models and methods to prevent and detect credit card fraud. Some credit card fraud transaction datasets contain the problem of imbalance in datasets. A good fraud detection system should be able to identify the fraud transaction accurately and should make the detection possible in real-time transactions.

>Fraudsters masquerade the normal behavior of customers and the fraud patterns are changing rapidly so the fraud detection system needs to constantly learn and update. Credit card fraud can be broadly classified into three categories, that is, traditional card-related frauds (application, stolen, account takeover, fake and counterfeit), merchant-related frauds (merchant collusion and triangulation) and Internet frauds (site cloning, credit card generators, BOT attacks, and false merchant sites).

>
The problem statement - Build a sustainable system/application for real-time fraud detection and prevention using historical transaction and demographic data with lower false positive and without impacting customer experience.

# 3.0 How to address the problem statement
>
Data analysis is an essential step in understanding any problem and developing effective solutions. Without proper data analysis, we may make assumptions or decisions that are not based on evidence and may not effectively address the underlying issues. By conducting thorough research and data analysis, we can identify patterns, trends, and relationships that can help us better understand the problem at hand. We can also verify any hypotheses we may have and test different solutions to determine their effectiveness.
>
Moreover, data analysis can provide valuable insights that can inform decision-making and help us develop data-driven solutions that are more likely to be successful. It can also help us identify gaps in our understanding and highlight areas where further research is needed.
>
Overall, data analysis is an essential tool for anyone looking to address complex problems effectively. It provides a solid foundation for decision-making and can help us develop more effective and efficient solutions that can lead to better outcomes for all stakeholders involved.

>
a.  To determine the percentage of fraud that can be detected or prevented using the AI/ML model, you can use historical data on fraudulent and non-fraudulent transactions to train the model. You can then use a hold-out set of data to evaluate the model's performance and calculate the percentage of fraud that can be detected or prevented.
>
b.  Data mining techniques can be used to detect financial fraud by analyzing patterns and anomalies in transaction data. You can use various algorithms such as clustering, decision trees, and neural networks to identify fraudulent transactions.
>
c.  To determine whether credit card fraud is impacting both consumers and merchants, you can analyze data on the number of reported fraudulent transactions and the financial losses incurred by both parties.
>
d.  To identify the latest fraud trends such as identity fraud, synthetic fraud, and card not present fraud, you can review industry reports and research papers on fraud detection.
>
e.  To determine the latest trends in credit card fraud, you can analyze data on the types of fraudulent transactions, the locations where fraud occurs, and the methods used by fraudsters.
>
f.  To identify gaps in existing fraud detection mechanisms, you can review industry reports and research papers on fraud detection and analyze the performance of existing fraud detection models.
>
g.  To identify impacted parties due to credit card fraud, you can analyze data on the number of reported fraudulent transactions and the financial losses incurred by consumers, merchants, and financial institutions.
>
h.  To determine the percentage of fraud detected or prevented using the existing AI and data model, you can use historical data to evaluate the performance of the existing model.
>
i.  To determine the state of credit card fraud detection, you can analyze industry reports on fraud detection and review research papers on the latest fraud detection techniques.
>
j.  To identify issues with credit card fraud detection, you can analyze the performance of existing fraud detection models and identify areas where the models are failing to detect fraudulent transactions.
>
k.  To identify possible future issues with credit card fraud detection, you can review industry reports and research papers on emerging fraud trends and analyze the performance of existing fraud detection models in detecting these new types of fraud.

>
Here I am planning to use dataset02 and create  model using RandomForest

# 4.0 Analysis & Modeling


```{r include = TRUE, warning = FALSE, comment = NA}
## Load the required packages(s)
library(dplyr) 
library(ggplot2) 
library(stringr) 
library(caret) 
library(caTools) 
library(corrplot) 
library(Rtsne) 
library(DMwR)
library(ROSE)
library(rpart)
library(Rborist)
library(xgboost)

## Set the working directory to the root of your DSC 520 directory
setwd("/Users/debam/OneDrive/Documents/GitHub/dsc520")
getwd()

## Load the dataset02
dataset02_df <- read.csv('data/Dataset02.csv')
```

## Data Exploration

```{r echo=TRUE, include=TRUE}
head(dataset02_df)
str(dataset02_df)
summary(dataset02_df)

## Check for  missing values
colSums(is.na(dataset02_df))

## Check for class imbalance
table(dataset02_df$Class)

## class imbalance in percentage
prop.table(table(dataset02_df$Class))

```

```{r echo=TRUE, include=TRUE}
common_theme <- theme(plot.title = element_text(hjust = 0.5, face = "bold"))

ggplot(data = dataset02_df, aes(x = factor(Class), 
                          y = prop.table(after_stat(count)), fill = factor(Class),
                          label = scales::percent(prop.table(after_stat(count))))) +
    geom_bar(position = "dodge") + 
    geom_text(stat = 'count',
              position = position_dodge(.9), 
              vjust = -0.5, 
              size = 3) + 
    scale_x_discrete(labels = c("no fraud", "fraud"))+
    scale_y_continuous(labels = scales::percent)+
    labs(x = 'Class', y = 'Percentage') +
    ggtitle("Distribution of class labels") +
    common_theme
```

>
This dataset is highly imbalanced, with the vast majority of transactions being non-fraudulent (99.8%). This makes accuracy an unsuitable metric for evaluating the performance of a classification model, as a model that always predicts non-fraudulent transactions would achieve high accuracy despite being ineffective in identifying actual fraudulent transactions. Instead, AUC (Area Under the Precision-Recall Curve) would be a more appropriate evaluation metric for this dataset, as it takes into account the true positive rate and the positive predictive value of the model, which are crucial for identifying the relatively rare instances of fraudulent transactions in the dataset.

\newpage

## Data Visualization

### Distribution of variable 'Time' by class :

```{r echo=TRUE, include=TRUE}
dataset02_df %>%
  ggplot(aes(x = Time, fill = factor(Class))) + geom_histogram(bins = 100)+
  labs(x = 'Time in seconds since first transaction', y = 'No. of transactions') +
  ggtitle('Distribution of time of transaction by class') +
  facet_grid(Class ~ ., scales = 'free_y') + common_theme
```

>
The ‘Time’ feature looks pretty similar across both types of transactions. One could argue that fraudulent transactions are more uniformly distributed, while normal transactions have a cyclical distribution

```{r echo=TRUE, include=TRUE}
ggplot(dataset02_df, aes(x = factor(Class), y = Amount)) + geom_boxplot() + 
labs(x = 'Class', y = 'Amount') +
ggtitle("Distribution of transaction amount by class") + common_theme
```

>
Fraudulent transactions may be characterized by unusually large or small transaction values compared to normal transactions. However, fraudsters may also try to disguise their activity by mimicking the behavior of normal transactions, so the variability in transaction values may not always be a reliable indicator of fraud. Based on above plot , there is more variability in the transaction values for non-fraudulent transactions.

\newpage

### Correlation of anonymised variables and 'Amount'

```{r echo=TRUE, include=TRUE}
correlations <- cor(dataset02_df[,-1],method="pearson")
corrplot(correlations, number.cex = .9, method = "circle", type = "full", tl.cex=0.8,tl.col = "black")
```

>
If the features V1 to V28 were generated by applying Principal Component Analysis (PCA) to the original features, then it's likely that these features represent a reduced set of dimensions that capture the most important variation in the original dataset. The numbering of the features in this case typically reflects the order of importance of the principal components, where V1 represents the principal component that captures the most variation, V2 represents the second most important component, and so on.

>
PCA is a technique that can be used to transform a set of correlated features into a set of uncorrelated features, known as principal components, while retaining most of the information in the original features. By doing so, it can reduce the dimensionality of the dataset and simplify the analysis.

>
However, it's important to note that the importance of the principal components may not always be reflected by their numbering. In some cases, the principal components may represent specific combinations of the original features that have high predictive power, even if they do not capture the most variation in the dataset. Therefore, it's important to analyze the data and the PCA results carefully to understand the relationship between the original features and the principal components, and to select the most relevant features for the analysis.

\newpage

### Visualization of transactions using t-SNE

```{r echo=TRUE, include=TRUE}
tsne_subset <- 1:as.integer(0.1*nrow(dataset02_df))
tsne <- Rtsne(dataset02_df[tsne_subset,-c(1, 31)], perplexity = 20, theta = 0.5, 
              pca = F, verbose = F, max_iter = 500, check_duplicates = F)

classes <- as.factor(dataset02_df$Class[tsne_subset])
tsne_mat <- as.data.frame(tsne$Y)

ggplot(tsne_mat, aes(x = V1, y = V2)) + geom_point(aes(color = classes)) + theme_minimal() + common_theme + 
ggtitle("t-SNE visualisation of transactions") +
scale_color_manual(values = c("#E69F00", "#56B4E9"))

```

>
Distributed Stochastic Neighbor Embedding (t-SNE) is a technique for visualizing high-dimensional data by mapping it to a lower-dimensional space, typically two or three dimensions, while preserving the local structure of the data. By doing so, it can reveal patterns and relationships in the data that may be difficult to detect using other methods.

>
Setting the perplexity parameter to 20 can be a good starting point, but it's important to experiment with different values to find the best configuration for the data. Perplexity is a hyper parameter that controls the balance between preserving the local structure of the data and spreading out the points in the low-dimensional space. A higher perplexity value can result in more global structure being preserved, while a lower value can result in more emphasis on local structure.

>
If the visualization reveals clear clusters or patterns in the data, it's a good sign that the data may be separable and that the model could learn to distinguish between normal and fraudulent transactions. However, if there is no obvious structure in the data, it may be more challenging for the model to identify meaningful patterns and perform well. There appears to be a separation between the two classes as most fraudulent transactions seem to lie near the edge of the blob of data.

>
Overall, t-SNE can be a useful tool for exploring and understanding high-dimensional datasets, but it's important to remember that it's only one of many techniques and should be used in conjunction with other analysis methods to gain a comprehensive understanding of the data.


## Modeling 

>
ML algorithms often face accuracy issues due to an uneven distribution of the dependent variable. As a result, existing classifiers tend to exhibit bias towards the majority class, as the algorithms prioritize accuracy and aim to minimize overall error, in which the minority class contributes very little. Moreover, ML algorithms assume that the data set has a balanced class distribution and that errors obtained from different classes have the same cost.
>
To address this issue, various methods have been developed, collectively known as "sampling methods". These methods generally aim to transform an imbalanced data set into a balanced distribution using a specific mechanism that alters the size of the original data set while maintaining the same proportion of balance.
>
Here I have used "Undersampling Oversampling Synthetic Data Generation" methods for this inbalance data set.
>
Undersampling involves randomly removing examples from the majority class to balance the data set. This technique can lead to a loss of information as valuable data may be removed, but it can be useful when the data set is too large.
>
Oversampling involves duplicating examples from the minority class to increase the number of examples. This can lead to overfitting, where the model learns to memorize the data instead of generalizing, but it can be useful when the data set is small.
>
Synthetic data generation involves creating new synthetic examples based on existing ones in the minority class. This can be done using techniques such as SMOTE (Synthetic Minority Over-sampling Technique), which creates synthetic examples by interpolating between existing minority class examples. This technique can be useful when the minority class has complex patterns that cannot be captured by simply duplicating examples.
>
Each of these techniques has its advantages and disadvantages, and the choice of which one to use depends on the specific problem being solved and the characteristics of the data set. A combination of these techniques may also be used to achieve the best performance.

\newpage

## Data Preparation
>
The "Time" feature does not provide information about the actual time of the transaction and instead merely lists the data in chronological order. After analyzing the data visualization, it appears that the "Time" feature has little to no importance in accurately classifying a fraudulent transaction. Therefore, we have decided to exclude this column from further analysis

```{r echo=TRUE, include=TRUE}
## Remove 'Time' variable
dataset02_df_mod <- dataset02_df[,-1]

#Change 'Class' variable to factor
dataset02_df_mod$Class <- as.factor(dataset02_df_mod$Class)
levels(dataset02_df_mod$Class) <- c("Not_Fraud", "Fraud")

#Scale numeric variables
dataset02_df_mod[,-30] <- scale(dataset02_df_mod[,-30])
head(dataset02_df_mod)
```

### Split data into train and test sets

```{r echo=TRUE, include=TRUE}
set.seed(123)
split <- sample.split(dataset02_df_mod$Class, SplitRatio = 0.7)
train <-  subset(dataset02_df_mod, split == TRUE)
test <- subset(dataset02_df_mod, split == FALSE)
```

### Choosing sampling technique

```{r echo=TRUE, include=TRUE}
table(train$Class)
```

### downsampling

```{r echo=TRUE, include=TRUE}
set.seed(9560)
down_train <- downSample(x = train[, -ncol(train)],y = train$Class)
table(down_train$Class)
```

### upsampling

```{r echo=TRUE, include=TRUE}
set.seed(9560)
up_train <- upSample(x = train[, -ncol(train)],y = train$Class)
table(up_train$Class)
```

### SMOTE
```{r echo=TRUE, include=TRUE}
set.seed(9560)
smote_train <- SMOTE(Class ~ ., data  = train)
table(smote_train$Class)
```

### ROSE
```{r echo=TRUE, include=TRUE}
set.seed(9560)
rose_train <- ROSE(Class ~ ., data  = train)$data 
table(rose_train$Class)
```


## Decision Trees
>
Prior to implementing sampling techniques, we will assess how CART performs on imbalanced data. We will utilize the "roc.curve" function from the ROSE package to evaluate the model's performance on the test set.


### Decision trees on original (imbalanced) dataset

```{r echo=TRUE, include=TRUE}
#CART Model Performance on imbalanced data
set.seed(5627)
orig_fit <- rpart(Class ~ ., data = train)

#Evaluate model performance on test set
pred_orig <- predict(orig_fit, newdata = test, method = "class")
roc.curve(test$Class, pred_orig[,2], plotit = TRUE)
```

>
To assess the model's performance on the test data, we will calculate the ROC AUC score. Our evaluation of the original dataset shows an AUC score of 0.912. We will proceed by implementing different sampling techniques on the data to observe the corresponding performance on the test set.

```{r echo=TRUE, include=TRUE}

# Build down-sampled model
set.seed(5627)
down_fit <- rpart(Class ~ ., data = down_train)

# Build up-sampled model
set.seed(5627)
up_fit <- rpart(Class ~ ., data = up_train)

# Build smote model
set.seed(5627)
smote_fit <- rpart(Class ~ ., data = smote_train)

# Build rose model
set.seed(5627)
rose_fit <- rpart(Class ~ ., data = rose_train)

# AUC on down-sampled data
pred_down <- predict(down_fit, newdata = test)

print('Fitting model to downsampled data')
roc.curve(test$Class, pred_down[,2], plotit = FALSE)

# AUC on up-sampled data
pred_up <- predict(up_fit, newdata = test)

print('Fitting model to upsampled data')
roc.curve(test$Class, pred_up[,2], plotit = FALSE)

# AUC on SMOTE data
pred_smote <- predict(smote_fit, newdata = test)

print('Fitting model to smote data')
roc.curve(test$Class, pred_smote[,2], plotit = FALSE)

# AUC on ROSE data
pred_rose <- predict(rose_fit, newdata = test)

print('Fitting model to rose data')
roc.curve(test$Class, pred_rose[,2], plotit = FALSE)

```

>
The sampling techniques have all resulted in higher AUC scores than the original imbalanced dataset. We will now evaluate different models using the up-sampling technique, which provided the highest AUC score.

\newpage

## Models on upsampled data

### Logistic Regression

```{r echo=TRUE, include=TRUE}

glm_fit <- glm(Class ~ ., data = up_train, family = 'binomial')

pred_glm <- predict(glm_fit, newdata = test, type = 'response')

roc.curve(test$Class, pred_glm, plotit = TRUE)

```

\newpage

### Random Forest

```{r echo=TRUE, include=TRUE}

x = up_train[, -30]
y = up_train[,30]

rf_fit <- Rborist(x, y, ntree = 1000, minNode = 20, maxLeaf = 13)


rf_pred <- predict(rf_fit, test[,-30], ctgCensus = "prob")


prob <- rf_pred$prob

roc.curve(test$Class, prob[,2], plotit = TRUE)

```

\newpage

### XGBoost

```{r echo=TRUE, include=TRUE}

# Convert class labels from factor to numeric
labels <- up_train$Class
y <- recode(labels, 'Not_Fraud' = 0, "Fraud" = 1)

set.seed(42)
xgb <- xgboost(data = data.matrix(up_train[,-30]), 
 label = y,
 eta = 0.1,
 gamma = 0.1,
 max_depth = 10, 
 nrounds = 300, 
 objective = "binary:logistic",
 colsample_bytree = 0.6,
 verbose = 0,
 nthread = 7,
)

xgb_pred <- predict(xgb, data.matrix(test[,-30]))
roc.curve(test$Class, xgb_pred, plotit = TRUE)
names <- dimnames(data.matrix(up_train[,-30]))[[2]]

# Compute feature importance matrix
importance_matrix <- xgb.importance(names, model = xgb)
xgb.plot.importance(importance_matrix[1:10,])

```

\newpage

# 5.0 Implications

>
The following are the overall implications of my report and analysis:
a.  The impact of different selected variables on dependent variables remains inconclusive.
b.  The variety, veracity, and value of the data are important considerations when dealing with complex data from multiple sources to ensure quality and accuracy of results.
c.  High-profile data breaches have exacerbated the data quality issue.
d.  Data sharing has become a sensitive topic, as inadequate sharing can result in criminal prosecution, reputational damage, or civil penalties.
e.  While data sharing is crucial for fraud detection and better service delivery, it is equally important for the sharing body to comply with relevant regulatory and legal requirements.
f.  Overall, the findings of this analysis suggest that additional research and analysis is necessary to gain a more comprehensive understanding of the data and its impact.


# 6.0 Implications

>
This analysis has some limitations, which include, but are not limited to:
>
a.  Insufficient data was available in some datasets to conduct a better longitudinal or time series analysis. More data across multiple years may lead to different findings than those present in this analysis.
b.  Changing fraud patterns over time are challenging to address since fraudsters always try to find new and innovative ways to bypass the system, resulting in decreased model performance and efficiency. Thus, machine learning models need regular updating to fulfill their objectives.
c.  Model interpretations pose a challenge since models typically provide a score without explaining why a transaction is likely to be fraudulent or not.
d.  The fact that yearly data did not match or was not the same across all variables is also a limitation. Additional sources of data with similar timeframes may be necessary.
e.  To answer one of the research questions, building a predictive model that uses historical data to forecast the future transaction set is recommended. This is crucial in understanding the future mode of the transaction set and how current actions may impact it.
>
Overall, this analysis is rudimentary in the grand scheme of research and data science, and additional studies are necessary to overcome these limitations and gain a better understanding of the data and its impact.

# 7.0 Concluding Remarks

>
The detection of credit card fraud is a serious issue that requires attention. In this project, we have explored various fraud detection methods and their detection techniques, and have reviewed recent findings in the field. The use of machine learning algorithms in fraud detection has been explained in detail, including the implementation of the algorithm, pseudocode, and experimentation results. However, due to the large imbalance between the number of valid and fraudulent transactions, the precision of the algorithm is arround 30% when the entire dataset is fed into it.
>
This project allows for the integration of multiple algorithms as modules, and their results can be combined to increase the accuracy of the final result. The modularity and versatility of the project allow for easy addition of more algorithms in the same format as the others. However, more data can improve the precision of the algorithms, as demonstrated by the increase in precision with larger datasets. Further improvement can be achieved by adding more algorithms and increasing the dataset size, leading to a more accurate detection of fraud and a reduction in false positives.
>
We have explained why accuracy cannot be relied upon as an appropriate measure of model performance in this scenario and instead utilized the AREA UNDER ROC CURVE metric to evaluate the effectiveness of various oversampling or undersampling techniques on the response variable. Our findings indicate that oversampling method works best on the dataset and has led to significant improvement in model performance as compared to the imbalanced data. The highest score of 0.977 was obtained using an XGBOOST model, although both random forest and logistic regression models also performed well. Further tuning of the XGBOOST model parameters may result in better performance. This project highlights the significance of effective sampling, modeling, and predicting data with an imbalanced dataset.


# 8.0 References

>
1. 	https://www.mygreatlearning.com/blog/credit-card-fraud-detection/
2. 	https://sdk.finance/all-you-need-to-know-about-machine-learning-based-fraud-detection-systems/
3. 	https://www.sciencedirect.com/topics/social-sciences/credit-card-fraud
4. 	https://www.ncbi.nlm.nih.gov/
5. 	https://www.frontiersin.org/
6.  A review of machine learning techniques for credit card fraud detection (2022) - https://www.sciencedirect.com/science/article/pii/S1364815220218120
7.  Deep learning-based credit card fraud detection: A comparative study (2022) - https://link.springer.com/article/10.1186/s40537-022-00189-3
8.  Anomaly detection in credit card transactions using deep neural networks (2022) - https://www.sciencedirect.com/science/article/pii/S136481522021466X
9.  A comparison of machine learning algorithms for credit card fraud detection (2022) - https://www.sciencedirect.com/science/article/pii/S1364815220214892